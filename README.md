# ğŸ§  LLM Training Copilot

> **A pre-flight check tool that predicts if your ML training will succeed BEFORE you waste hours on a failed run.**

Built with **Gemini 3** for the Google AI Hackathon.

---

## ğŸ¯ The Problem

Training LLMs often fails due to:
- **OOM crashes** â€” Out of memory errors 2 hours into training
- **Overfitting** â€” Model memorizes instead of learning
- **Wrong hyperparameters** â€” Training never converges
- **Time miscalculations** â€” "Quick run" takes 3 days

You only discover these **after** training starts. This tool tells you **before**.

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ”¬ **Multi-AI Analysis** | 3 specialist Gemini 3 agents: Hardware Analyst, Training Analyst, Chief Analyst |
| ğŸ“Š **Pre-flight Predictions** | Memory usage, failure modes, training time, overfitting risk |
| â“ **Explain Buttons** | Click â“ on any section for detailed explanation |
| ğŸ’¬ **Smart Chat** | Ask configuration questions â€” AI answers with calculations |
| ğŸ“œ **History & Compare** | Save configs, compare side-by-side |
| ğŸ”‘ **Demo Mode** | Works without API key for judges to test |

---

## ğŸ§  How Multi-AI Reasoning Works

```
User Config â†’ [Hardware Analyst] â†’ Memory calculations
           â†’ [Training Analyst] â†’ Hyperparameter analysis
                     â†“
              [Chief Analyst] â†’ Synthesized verdict
                     â†“
           âœ… Safe / âš ï¸ Risky / âŒ Will Fail
```

Each specialist focuses on its domain. The Chief Analyst combines their reasoning into actionable advice.

---

## ğŸ–¥ï¸ Screenshots

*[Add screenshots here]*

---

## ğŸš€ Quick Start

```bash
# Clone the repo
git clone <repo-url>
cd llm-training-analyzer

# Install dependencies
npm install

# Run development server
npm run dev
```

Visit `http://localhost:5173`

### Using the API

1. Get a Gemini API key from [AI Studio](https://aistudio.google.com/apikey)
2. Enter it in the header input
3. Run analysis with real Gemini 3 reasoning

---

## ğŸ› ï¸ Tech Stack

- **Frontend**: React + Vite
- **AI**: Gemini 3 API (Pro for Reasoning Council, Flash for Chat)
- **Styling**: Custom CSS, dark theme

---

## ğŸ“ Usage

1. **Configure** â€” Fill in GPU, model, training parameters
2. **Analyze** â€” Click "Analyze Configuration"
3. **Review** â€” Check predictions across all sections
4. **Ask** â€” Click â“ for explanations or chat for follow-ups
5. **Iterate** â€” Adjust config, analyze again, compare results

---

## ğŸ¯ Target Users

- Engineers configuring LLM fine-tuning
- Researchers working with limited GPU resources
- Students experimenting with low-resource language models

---

## ğŸ“¦ Project Structure

```
src/
â”œâ”€â”€ App.jsx              # Main app with state management
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ConfigPanel.jsx  # Left panel - configuration inputs
â”‚   â”œâ”€â”€ ReasoningPanel.jsx # Center panel - analysis results
â”‚   â””â”€â”€ ChatPanel.jsx    # Right panel - AI chat
â”œâ”€â”€ services/
â”‚   â””â”€â”€ gemini.js        # Gemini 3 API integration
â”œâ”€â”€ data/
â”‚   â””â”€â”€ presets.js       # GPU/Model presets, demo responses
â””â”€â”€ index.css            # Styling
```

---

## ğŸ† Built For

**Google Gemini 3 API Developer Competition**

This project demonstrates Gemini 3's capability for:
- Structured reasoning across multiple domains
- Technical analysis with calculations
- Conversational follow-up with context retention

---

## ğŸ“„ License

MIT
